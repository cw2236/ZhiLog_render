import os
import boto3
from botocore.exceptions import ClientError
import mimetypes
from pathlib import Path

# AWS é…ç½® - ä½¿ç”¨ç¯å¢ƒå˜é‡
AWS_CONFIG = {
    'aws_access_key_id': os.environ.get('AWS_ACCESS_KEY_ID'),
    'aws_secret_access_key': os.environ.get('AWS_SECRET_ACCESS_KEY'),
    'region_name': os.environ.get('AWS_REGION', 'us-east-2'),
    'bucket_name': os.environ.get('AWS_BUCKET_NAME', 'zhilog1'),
    'prefix': os.environ.get('AWS_PREFIX', 'papers/')
}

# æœ¬åœ°æ–‡ä»¶ç›®å½•
LOCAL_PDF_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'static', 'pdf')

def test_s3_connection():
    """æµ‹è¯• S3 è¿æ¥"""
    try:
        s3_client = boto3.client(
            's3',
            aws_access_key_id=AWS_CONFIG['aws_access_key_id'],
            aws_secret_access_key=AWS_CONFIG['aws_secret_access_key'],
            region_name=AWS_CONFIG['region_name']
        )
        
        # æµ‹è¯•åˆ—å‡ºå­˜å‚¨æ¡¶
        s3_client.head_bucket(Bucket=AWS_CONFIG['bucket_name'])
        print("âœ… S3 è¿æ¥æµ‹è¯•æˆåŠŸï¼")
        return s3_client
    except ClientError as e:
        print(f"âŒ S3 è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return None

def migrate_files(s3_client):
    """è¿ç§»æ–‡ä»¶åˆ° S3"""
    if not s3_client:
        return
    
    success_count = 0
    error_count = 0
    skipped_count = 0
    
    # ç¡®ä¿æœ¬åœ°ç›®å½•å­˜åœ¨
    if not os.path.exists(LOCAL_PDF_DIR):
        print(f"âŒ æœ¬åœ°ç›®å½•ä¸å­˜åœ¨: {LOCAL_PDF_DIR}")
        return
    
    # è·å–å·²æœ‰çš„ S3 æ–‡ä»¶åˆ—è¡¨
    try:
        existing_files = set()
        paginator = s3_client.get_paginator('list_objects_v2')
        for page in paginator.paginate(Bucket=AWS_CONFIG['bucket_name'], Prefix=AWS_CONFIG['prefix']):
            if 'Contents' in page:
                for obj in page['Contents']:
                    existing_files.add(obj['Key'])
    except ClientError as e:
        print(f"âŒ è·å– S3 æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
        return

    # éå†æœ¬åœ°æ–‡ä»¶
    for file_path in Path(LOCAL_PDF_DIR).glob('**/*'):
        if not file_path.is_file():
            continue
            
        relative_path = file_path.relative_to(LOCAL_PDF_DIR)
        s3_key = f"{AWS_CONFIG['prefix']}{relative_path}"
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨äº S3
        if s3_key in existing_files:
            print(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶: {relative_path}")
            skipped_count += 1
            continue
            
        try:
            # è·å–æ–‡ä»¶ç±»å‹
            content_type = mimetypes.guess_type(file_path)[0] or 'application/octet-stream'
            
            # ä¸Šä¼ æ–‡ä»¶
            print(f"â¬†ï¸ ä¸Šä¼ : {relative_path}")
            with open(file_path, 'rb') as f:
                s3_client.upload_fileobj(
                    f,
                    AWS_CONFIG['bucket_name'],
                    s3_key,
                    ExtraArgs={
                        'ContentType': content_type,
                        'ACL': 'private'
                    }
                )
            success_count += 1
            
            # æµ‹è¯•ç”Ÿæˆé¢„ç­¾å URL
            url = s3_client.generate_presigned_url(
                'get_object',
                Params={
                    'Bucket': AWS_CONFIG['bucket_name'],
                    'Key': s3_key
                },
                ExpiresIn=3600
            )
            print(f"ğŸ”— é¢„ç­¾å URL ç”ŸæˆæˆåŠŸ: {url[:100]}...")
            
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥ {relative_path}: {e}")
            error_count += 1
    
    print(f"\nğŸ“Š è¿ç§»å®Œæˆ:")
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±è´¥: {error_count}")
    print(f"â­ï¸ è·³è¿‡: {skipped_count}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ S3 æ–‡ä»¶è¿ç§»...")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not AWS_CONFIG['aws_access_key_id'] or not AWS_CONFIG['aws_secret_access_key']:
        print("âŒ è¯·è®¾ç½® AWS_ACCESS_KEY_ID å’Œ AWS_SECRET_ACCESS_KEY ç¯å¢ƒå˜é‡")
        return
    
    # æµ‹è¯•è¿æ¥
    s3_client = test_s3_connection()
    if not s3_client:
        return
    
    # æ‰§è¡Œè¿ç§»
    migrate_files(s3_client)

if __name__ == "__main__":
    main()
